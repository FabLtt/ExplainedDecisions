{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scope: Prediction performance on crossed expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle   \n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category =RuntimeWarning)\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of decision timescale (NameHorizon), sampling time (NameStep) and expertise (NameExpertiseAndStep) to be used to loop over trained ANN models and computed cross performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NameHorizon = ['1', '8', '16', '32']\n",
    "\n",
    "NameStep = ['step1', 'step2', 'step4','step1', 'step2', 'step4']\n",
    "\n",
    "NameExertiseAndStep = ['Novice_step1', 'Novice_step2', 'Novice_step4', \n",
    "                      'Expert_step1', 'Expert_step2', 'Expert_step4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of ANN trained and samples used for each combination of sampling time, decision horizon and expertise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './checkpoint/FinalModels/'\n",
    "\n",
    "Novice_step1_set = [directory + '15032021/TrainTestSets_reduced3_indexes_001', \n",
    "                directory + '11032021/TrainTestSets_reduced3_indexes_004',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_001',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_001']\n",
    "\n",
    "Novice_step2_set = [directory + '11032021/TrainTestSets_reduced3_indexes_002', \n",
    "                directory + '11032021/TrainTestSets_reduced3_indexes_005',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_002',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_002']\n",
    "\n",
    "Novice_step4_set = [directory + '11032021/TrainTestSets_reduced3_indexes_003', \n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_008',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_003',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_003']\n",
    "\n",
    "Expert_step1_set = [directory + '12032021/TrainTestSets_reduced3_indexes_001', \n",
    "                directory + '12032021/TrainTestSets_reduced3_indexes_004',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_004',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_004']\n",
    "\n",
    "Expert_step2_set = [directory + '12032021/TrainTestSets_reduced3_indexes_002', \n",
    "                directory + '12032021/TrainTestSets_reduced3_indexes_005',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_005',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_005']\n",
    "\n",
    "Expert_step4_set = [directory + '12032021/TrainTestSets_reduced3_indexes_003', \n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_007',\n",
    "                directory + '13032021/TrainTestSets_reduced3_indexes_006',\n",
    "                directory + '14032021/TrainTestSets_reduced3_indexes_006']\n",
    "\n",
    "file_set_list = [Novice_step1_set, Novice_step2_set, Novice_step4_set, Expert_step1_set, Expert_step2_set, Expert_step4_set]\n",
    "\n",
    "Novice_step1_model = [directory + '15032021/15032021001_reduced3', \n",
    "            directory + '11032021/11032021004_reduced3',\n",
    "            directory + '13032021/13032021001_reduced3',\n",
    "            directory + '14032021/14032021001_reduced3']\n",
    "\n",
    "Novice_step2_model = [directory + '11032021/11032021002_reduced3', \n",
    "                directory + '11032021/11032021005_reduced3',\n",
    "                directory + '13032021/13032021002_reduced3',\n",
    "                directory + '14032021/14032021002_reduced3']\n",
    "\n",
    "Novice_step4_model = [directory + '11032021/11032021003_reduced3', \n",
    "                directory + '13032021/13032021008_reduced3',\n",
    "                directory + '13032021/13032021003_reduced3',\n",
    "                directory + '14032021/14032021003_reduced3']\n",
    "\n",
    "Expert_step1_model = [directory + '12032021/12032021001_reduced3', \n",
    "                directory + '12032021/12032021004_reduced3',\n",
    "                directory + '13032021/13032021004_reduced3',\n",
    "                directory + '14032021/14032021004_reduced3']\n",
    "\n",
    "Expert_step2_model = [directory + '12032021/12032021002_reduced3', \n",
    "                directory + '12032021/12032021005_reduced3',\n",
    "                directory + '13032021/13032021005_reduced3',\n",
    "                directory + '14032021/14032021005_reduced3']\n",
    "\n",
    "Expert_step4_model = [directory + '12032021/12032021003_reduced3', \n",
    "                directory + '13032021/13032021007_reduced3',\n",
    "                directory + '13032021/13032021006_reduced3',\n",
    "                directory + '14032021/14032021006_reduced3']\n",
    "\n",
    "file_model_list = [Novice_step1_model, Novice_step2_model, Novice_step4_model, \n",
    "                   Expert_step1_model, Expert_step2_model, Expert_step4_model]\n",
    "\n",
    "\n",
    "file_sequences_directory = './dataset/sequences/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_horizon = 0\n",
    "# key_expstep = 0\n",
    "# key_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging cell\n",
    "# NameExertiseAndStep[key_expstep] , NameExertiseAndStep[key_test] , NameStep[key_expstep], NameStep[key_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_horizon in range(len(NameHorizon)):\n",
    "    for key_expstep in range(len(NameExertiseAndStep)):\n",
    "        for key_test in range(len(NameExertiseAndStep)):\n",
    "            \n",
    "            # Check if sampling time and decision horizon of training and test set coincide\n",
    "            # otherwise skip forward\n",
    "            if NameStep[key_expstep] == NameStep[key_test]:\n",
    "\n",
    "                print('\\n')\n",
    "                print(NameExertiseAndStep[key_expstep] , NameExertiseAndStep[key_test] , NameStep[key_expstep], \n",
    "                      NameStep[key_test])\n",
    "\n",
    "                # load the model \n",
    "                file_to_open = file_set_list[key_expstep][key_horizon]\n",
    "                file_model = file_model_list[key_expstep][key_horizon]\n",
    "\n",
    "                #load training and test samples\n",
    "                file_sequences = file_sequences_directory + 'SequencesTargets_'+ NameExertiseAndStep[key_test]+'_'+NameHorizon[key_horizon]\n",
    "\n",
    "\n",
    "                SeqTarList_file = open(file_sequences,\"rb\")\n",
    "                SeqTarList = pickle.load(SeqTarList_file)\n",
    "                SeqTarList_file.close()\n",
    "\n",
    "                sequences = SeqTarList[0]\n",
    "                targets = SeqTarList[1]\n",
    "\n",
    "                sequences_array = np.array(sequences)\n",
    "                targets_array = np.array(targets)\n",
    "                \n",
    "                # if training and test sets' expertise coincide, load test samples from the corresponding file\n",
    "                # otherwise randomly select test_size = 2000 samples from the opposite expertise (same decision \n",
    "                # horizon and sampling time)\n",
    "                if NameExertiseAndStep[key_expstep][:6] == NameExertiseAndStep[key_test][:6]: \n",
    "\n",
    "                    TrainTestSets_file = open(file_to_open,\"rb\")\n",
    "                    indexes_data = pickle.load(TrainTestSets_file)\n",
    "                    TrainTestSets_file.close()\n",
    "\n",
    "                    test_index = indexes_data[1]\n",
    "\n",
    "                    X_test = sequences_array[test_index]\n",
    "                    y_test = targets_array[test_index] \n",
    "\n",
    "                else: \n",
    "                    print('Not matching!')\n",
    "\n",
    "                    sss = StratifiedShuffleSplit(train_size=10, n_splits=1, \n",
    "                                         test_size=2000, random_state=0)  \n",
    "\n",
    "                    for train_index, test_index in sss.split(sequences_array, targets_array):\n",
    "                        X_train, X_test = sequences_array[train_index], sequences_array[test_index]\n",
    "                        y_train, y_test = targets_array[train_index], targets_array[test_index]\n",
    "\n",
    "                dummies_test = pd.get_dummies(y_test)\n",
    "\n",
    "                test = X_test\n",
    "                test_target = dummies_test.values\n",
    "                \n",
    "                # Load the trained ANN \n",
    "                model = load_model(file_model)\n",
    "                \n",
    "                # Use the trained ANN on the test set  \n",
    "                test_preds = model.predict(test)\n",
    "\n",
    "                # Compute metrics for the trained ANN \n",
    "                predicted_classes = np.argmax(test_preds,axis=1)\n",
    "                expected_classes = np.argmax(test_target,axis=1)\n",
    "                correct = metrics.accuracy_score(expected_classes,predicted_classes)\n",
    "\n",
    "                print(\"Accuracy: %.2f%%\" % (correct*100))\n",
    "\n",
    "                precision_recall_f1 = metrics.precision_recall_fscore_support(expected_classes,predicted_classes)\n",
    "\n",
    "                precision = 0\n",
    "                recall = 0\n",
    "                f1 = 0\n",
    "\n",
    "                for i in range (5): \n",
    "                    precision = precision + precision_recall_f1[0][i]\n",
    "                    recall = recall + precision_recall_f1[1][i]\n",
    "                    f1 = f1 + precision_recall_f1[2][i]\n",
    "\n",
    "                kappascore = metrics.cohen_kappa_score(expected_classes, predicted_classes)\n",
    "                \n",
    "#                 # Save performance metrics in .mat file to prepare MATLAB plots \n",
    "#                 matLabel = NameExertiseAndStep[key_expstep][:6] + \"_\" + NameExertiseAndStep[key_test] \n",
    "#                 + \"_Horizon\" + NameHorizon[key_horizon]\n",
    "\n",
    "#                 matDict = {\"accuracy_\"+matLabel: correct*100, \"precision_\"+matLabel: precision*100 / 5, \n",
    "#                            \"recall_\"+matLabel : recall*100 / 5, \"f1score_\"+matLabel : f1*100 / 5, \n",
    "#                            \"Kscore_\"+matLabel : kappascore}\n",
    "\n",
    "#                 savemat(matLabel+\".mat\", matDict)\n",
    "#                 print(matLabel)\n",
    "\n",
    "            else:\n",
    "                print('------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP documentation available at : https://github.com/slundberg/shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle  \n",
    "from sklearn import metrics\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category =RuntimeWarning)\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check TensorFlow and SHAP version for compatibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__ , shap.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the dataset file ('file'), the training and test indexes file ('file_to_open') and the model file ('file_model')\n",
    "- Select the decision horizon ('look_forward')\n",
    "- Select the sampling time ('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./dataset/DatasetFileMultiClassPred_BothHerders_WrtGoal_Extended_step2\",\"rb\")\n",
    " \n",
    "look_forward = 1\n",
    "\n",
    "step = \"\"\n",
    "\n",
    "directory = './checkpoint/FinalModels/'\n",
    "file_to_open = open(directory + '11032021/TrainTestSets_reduced3_indexes_002',\"rb\")\n",
    "file_model = directory + '11032021/11032021002_reduced3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and select the columns referred by 'Labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ['h_t0 rel dist', 'h_t1 rel dist', 'h_t2 rel dist', 'h_t3 rel dist', 'h_t0 rel angle', 'h_t1 rel angle', \n",
    "          'h_t2 rel angle', 'h_t3 rel angle', \n",
    "      'h_goal rel dist', 't0_goal rel dist', 't1_goal rel dist', 't2_goal rel dist', 't3_goal rel dist',\n",
    "      'h vel_r' , 't0 vel_r' , 't1 vel_r' , 't2 vel_r' ,  't3 vel_r' , \n",
    "      'h acc_r', 't0 acc_r', 't1 acc_r', 't2 acc_r', 't3 acc_r', \n",
    "      'h_goal_th', 't0_goal_th', 't1_goal_th', 't2_goal_th', 't3_goal_th', \n",
    "      'h_dir_motion', 't0_dir_motion', 't1_dir_motion', 't2_dir_motion', 't3_dir_motion',\n",
    "      'h_h1 rel dist', 'h_h1 rel angle', 'h1_goal rel dist', 'h1 vel_r', 'h1 acc_r',\n",
    "      'h1_goal_th', 'h1_dir_motion', 'h1_t0 rel dist', 'h1_t1 rel dist', 'h1_t2 rel dist', 'h1_t3 rel dist', \n",
    "      'h1_t0 rel angle', 'h1_t1 rel angle', 'h1_t2 rel angle', 'h1_t3 rel angle','Label']\n",
    "\n",
    "Labels.insert(0,\"Herder_id\")\n",
    "Labels.insert(1,\"Trial_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_full_df = pickle.load(file)\n",
    "    \n",
    "Dataset_df = Dataset_full_df[Labels]\n",
    "\n",
    "n_features = len(Dataset_df.columns) - 3\n",
    "print(\"there are \", n_features,\" features!\")\n",
    "\n",
    "Dataset = Dataset_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the sequences of features and target outputs from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1, look_forward=1):\n",
    "    dataX, dataY, dataZ = [], [], []\n",
    "    for i in range(len(dataset)-look_back-look_forward):\n",
    "        a = dataset[i:(i+look_back), :-1]\n",
    "        b = dataset[i:(i+look_back+look_forward), -1]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back + look_forward, -1])\n",
    "        dataZ.append(b)\n",
    "    return dataX, dataY, dataZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 25 # Sequence length\n",
    "\n",
    "sequences = []\n",
    "sequences_labels = []\n",
    "targets = []\n",
    "\n",
    "# A sequence can refer to only one Herder ID and one Trial ID\n",
    "\n",
    "herders_tot = int(max(Dataset[:,0]))\n",
    "trial_tot = int(max(Dataset[:,1]))\n",
    "\n",
    "for herder_id in range(herders_tot):\n",
    "    for trial_id in range(trial_tot):\n",
    "        Dtst = Dataset_df[(Dataset_df[\"Herder_id\"]==herder_id) & (Dataset_df[\"Trial_id\"]==trial_id)].values[:,2:]\n",
    "        seq, tar, seq_lbl = create_dataset(Dtst, look_back, look_forward)\n",
    "        sequences = sequences + seq\n",
    "        targets = targets + tar\n",
    "        sequences_labels = sequences_labels + seq_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select from the total available samples the ones used for training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_data = pickle.load(file_to_open)\n",
    "file_to_open.close()\n",
    "\n",
    "test_index = indexes_data[1]\n",
    "\n",
    "sequences_array = np.array(sequences)\n",
    "sequences_labels_array = np.array(sequences_labels)\n",
    "targets_array = np.array(targets)\n",
    "\n",
    "X_test = sequences_array[test_index]\n",
    "y_test = targets_array[test_index]\n",
    " \n",
    "dummies_test = pd.get_dummies(y_test)\n",
    "\n",
    "test = X_test\n",
    "test_target = dummies_test.values\n",
    "\n",
    "z_test_index = test_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to which type the test samples belong to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that  a \"sequence of labels\" has 26 elements being the labels of the 25 timestamps in the sequence and the 26th \n",
    "timestep corresponding to the target value to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test = []\n",
    "Z_test = sequences_labels_array[z_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SameSeq_SameTar_indexes = []         # indexes of sequences/targets with all equal labels \n",
    "test_SameSeq_DiffTar_indexes = []         # indexes of sequences with equal labels but different target\n",
    "test_DiffSeq_SameTar_indexes = []         # indexes of sequences with different labels but 25th label equale to the target\n",
    "test_DiffSeq_DiffTar_indexes = []         # indexex of sequences/targets with all different labels\n",
    "\n",
    "\n",
    "for i in range(len(Z_test)): \n",
    "    \n",
    "    arr = Z_test[i]\n",
    "\n",
    "    result_SameSeq_SameTar = np.all(arr == arr[0])\n",
    "    result_SameSeq_DiffTar = np.all(arr[:-1] == arr[0]) & (arr[-1] != arr[-2])\n",
    "    result_DiffSeq_SameTar = np.any(arr[:-1] != arr[0]) & (arr[-1] == arr[-2])\n",
    "    result_DiffSeq_DiffTar = np.any(arr[:-1] != arr[0]) & (arr[-1] != arr[-2])\n",
    "    \n",
    "    \n",
    "    if result_SameSeq_SameTar:\n",
    "        test_SameSeq_SameTar_indexes.append(i)\n",
    "    if result_SameSeq_DiffTar:\n",
    "        test_SameSeq_DiffTar_indexes.append(i)\n",
    "    if result_DiffSeq_SameTar:\n",
    "        test_DiffSeq_SameTar_indexes.append(i)\n",
    "    if result_DiffSeq_DiffTar:\n",
    "        test_DiffSeq_DiffTar_indexes.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non trasitioning and non switching sequences %0.2f\" %(len(test_SameSeq_SameTar_indexes)/len(test_index)*100))\n",
    "print(\"Non Transitioning and switching sequences %0.2f\" %(len(test_SameSeq_DiffTar_indexes)/len(test_index)*100))\n",
    "print(\"Transitioning and non switching sequences %0.2f\" %(len(test_DiffSeq_SameTar_indexes)/len(test_index)*100))\n",
    "print(\"Transitioning and switching sequences %0.2f\" %(len(test_DiffSeq_DiffTar_indexes)/len(test_index)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = X_test\n",
    "test_set_target = dummies_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trained ANN on the test set and Compute metrics for the trained ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_set)\n",
    "\n",
    "predicted_classes = np.argmax(test_preds,axis=1)\n",
    "expected_classes = np.argmax(test_set_target,axis=1)\n",
    "correct = metrics.accuracy_score(expected_classes,predicted_classes)\n",
    "\n",
    "print(\"------ Accuracy: %.2f%%\" % (correct*100))\n",
    "\n",
    "precision_recall_f1 = metrics.precision_recall_fscore_support(expected_classes,predicted_classes)\n",
    "\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1 = 0\n",
    "\n",
    "for i in range (5): \n",
    "    precision = precision + precision_recall_f1[0][i]\n",
    "    recall = recall + precision_recall_f1[1][i]\n",
    "    f1 = f1 + precision_recall_f1[2][i]\n",
    "\n",
    "print(\"Macro-Precision: %.2f%%\" % (precision*100 / 5))\n",
    "print(\"-- Macro-Recall: %.2f%%\" % (recall*100 / 5))\n",
    "print(\"------ Macro-F1: %.2f%%\" % (f1*100 /5))\n",
    "\n",
    "kappascore = metrics.cohen_kappa_score(expected_classes, predicted_classes)\n",
    "print(\"---- KappaScore: %.2f%%\" % (kappascore*100))\n",
    "\n",
    "confusionMatrix = metrics.confusion_matrix(expected_classes, predicted_classes, normalize='true')\n",
    "metrics.ConfusionMatrixDisplay(confusionMatrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SHAP values' file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_shap = file_model+'_ShapVal'\n",
    "\n",
    "with open(file_name_shap,'rb') as file:\n",
    "    shap_values = pickle.load(file)\n",
    "    \n",
    "shap_values = shap_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.initjs()   # uncomment this line to display SHAP plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class, compute the mean of shap values associated to each input features and display the top 10 [https://github.com/slundberg/shap/issues/632]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "feat_list = []\n",
    "\n",
    "for class_id in range(5):\n",
    "    vals = np.abs(shap_values[class_id]).mean(0)\n",
    "    feature_importance = pd.DataFrame(list(zip(Labels[2:-1], sum(vals))), columns=['var','feature_importance_vals_class'+str(class_id)])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals_class'+str(class_id)], ascending=False,inplace=True)\n",
    "    feat_list.append(feature_importance.values[:10,0])\n",
    "    print('\\n class ', class_id)\n",
    "    print(feature_importance.values[:10,0],\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
